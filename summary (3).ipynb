{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Balaji Padamwar\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import numpy as np\n",
    "import language_check\n",
    "import torch\n",
    "import math\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertSent_embeding(sentences):\n",
    "\n",
    "    ## Add sentence head and tail as BERT requested\n",
    "    marked_sent = [\"[CLS] \" +item + \" [SEP]\" for item in sentences]\n",
    "    \n",
    "    ## USE Bert tokenizization \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenized_sent = [tokenizer.tokenize(item) for item in marked_sent]\n",
    "    \n",
    "    ## index to BERT vocabulary\n",
    "    indexed_tokens = [tokenizer.convert_tokens_to_ids(item) for item in tokenized_sent]\n",
    "    tokens_tensor = [torch.tensor([item]) for item in indexed_tokens]\n",
    "    \n",
    "    ## add segment id as BERT requested\n",
    "    segments_ids = [[1] * len(item) for ind,item in enumerate(tokenized_sent)]\n",
    "    segments_tensors = [torch.tensor([item]) for item in segments_ids]\n",
    "    \n",
    "    ## load BERT base model and set to evaluation mode\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_model.eval()\n",
    "    \n",
    "    ## Output 12 layers of latent vector\n",
    "    assert len(tokens_tensor) == len(segments_tensors)\n",
    "    encoded_layers_list = []\n",
    "    for i in range(len(tokens_tensor)):\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = bert_model(tokens_tensor[i], segments_tensors[i])\n",
    "        encoded_layers_list.append(encoded_layers)\n",
    "    \n",
    "    ## Use only the last layer vetcor, other choice available\n",
    "    token_vecs_list = [layers[11][0] for layers in encoded_layers_list]\n",
    "    \n",
    "    ## Pooling word vector to sentence vector, use mean pooling, other choice available\n",
    "    sentence_embedding_list = [torch.mean(vec, dim=0).numpy() for vec in token_vecs_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return sentence_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_sumIndex(sentence_embedding_list):\n",
    "    \n",
    "    n_clusters = np.ceil(len(sentence_embedding_list)**0.5)\n",
    "    kmeans = KMeans(n_clusters=int(n_clusters))\n",
    "    kmeans = kmeans.fit(sentence_embedding_list)\n",
    "    \n",
    "    sum_index,_ = pairwise_distances_argmin_min(kmeans.cluster_centers_, sentence_embedding_list,metric='euclidean')\n",
    "    \n",
    "    sum_index = sorted(sum_index)\n",
    "    \n",
    "    return sum_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertSummarize(text):\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    #print(sentences)\n",
    "    sentence_embedding_list = bertSent_embeding(sentences)\n",
    "    #print(sentence_embedding_list)\n",
    "    #print(\"hi\")\n",
    "    sum_index = kmeans_sumIndex(sentence_embedding_list)\n",
    "    summary = ' '.join([sentences[ind] for ind in sum_index])\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"Hello this is Balaji Pado from the team's parking newbies with my teammates exam Pareek and Kishan Pathani and not topic for project is sentiment analysis of covid-19 tweets visualisation dashpot. So this is the URL of a project which is made using flask and other tools so my want to the first tape that it takes so here person can manually type in the sentiment of any other statements and then there is a prediction of that statement whether it is positive or negative so let's. Let's I am Corona positive patients see the statement is actually negative and it is also the negative symbol is it means that this model is a having a good accuracy and prediction by this modern is of symmetry near 200 which is a good score. So what we are doing in next part is that we are scraping live tweets and then will predict the sentiment of those trips. So how will do that is will search for covid-19 tweets will scrape the twits and Infratech and we can see there are three sections the tweet the time and date and the sentiment of the twits. So here we have also add add one more unique feature that is text to audio so it will convert the result in audio. Let's scraper life that we can see it that way it is script this is a live to it and will when will click on text to audio will use gtts and the same script to it will be converted to audio order food. In terms of the Desolation part it consists of the live graph graph update daily on clicking the refresh button. Once you click the refresh button the code runs in the back and forth in the grass is updated on completely remove wrinkles on the screen the dashboard is displayed of debit card on refreshing as I have clicked this it would show the live updates itself and now you can see that the life graphics. silvarpatti of the negative reactions of the people that is negative weight while the golden path is of depositing and there in this graph the Blue button positive with the red part is for the negative it. In this dashboard Park again this is the mode It is there is the difference of whs dashboard and the billiard sentence about us and it also contains the contact us feature and also our profile of various social media effect. This whole web page is designed using the HTML as well as the part which book particularly is the contribution in our project by that member. So this is all about of sentiment analysis project. Thank you \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractive_summary(text) ->str:\n",
    "    a=bertSummarize(text)\n",
    "    tool = language_check.LanguageTool('en-US')\n",
    "    matches1 = tool.check(a)\n",
    "    return language_check.correct(a, matches1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractive_summary(text) -> str:\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "    device = torch.device('cpu')\n",
    "    preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "    t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "    tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "    # summmarize \n",
    "    summary_ids = model.generate(tokenized_text,num_beams=3,no_repeat_ngram_size=1,min_length=50, max_length=100,early_stopping=True)\n",
    "    tool = language_check.LanguageTool('en-US')\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    matches2 = tool.check(output)\n",
    "    return language_check.correct(output, matches2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-small were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 9, 13]\n"
     ]
    }
   ],
   "source": [
    "abstractive=abstractive_summary(text)\n",
    "extractive =extractive_summary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extractive Summary: \n",
      "So this is the URL of a project which is made using flask and other tools so my want to the first tape that it takes so here person can manually type in the sentiment of any other statements and then there is a prediction of that statement whether it is positive or negative so lets. So what we are doing in next part is that we are scraping live tweets and then will predict the sentiment of those trips. Silvarpatti of the negative reactions of the people that is negative weight while the golden path is of depositing and there in this graph the Blue button positive with the red part is for the negative it. Thank you\n",
      "\n",
      "Abstractive Summary: \n",
      "Sentiment analysis of covid-19 tweets visualization dash pot is topic for project. So we are scraping live twitter and then will predict that statement, whether it was positive or negative in the next part to be used by people who have been on social media sites since 2000-2001 as an example from our own team with my teammates exam Park/Indian Nathan (I'm Corona positive patients)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExtractive Summary: \")\n",
    "print(extractive)\n",
    "print(\"\\nAbstractive Summary: \")\n",
    "print(abstractive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"myfile1.txt\",\"w+\",encoding=\"latin-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "b=\"\"\n",
    "j=0\n",
    "for i in extractive:\n",
    "    j=j+1\n",
    "    if j==130:\n",
    "        b=b+i\n",
    "        l.append(b)\n",
    "        l.append(\"\\n\")\n",
    "        b=\"\"\n",
    "        j=1\n",
    "    else:\n",
    "        b=b+i\n",
    "l.append(b)\n",
    "file1.writelines(l)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"myfile2.txt\",\"w+\",encoding=\"latin-1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "b=\"\"\n",
    "j=0\n",
    "for i in abstractive:\n",
    "    j=j+1\n",
    "    if j==130:\n",
    "        b=b+i\n",
    "        l.append(b)\n",
    "        l.append(\"\\n\")\n",
    "        b=\"\"\n",
    "        j=1\n",
    "    else:\n",
    "        b=b+i\n",
    "l.append(b)\n",
    "file2.writelines(l)\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python program to convert \n",
    "# text file to pdf file \n",
    "\n",
    "\n",
    "from fpdf import FPDF \n",
    "\n",
    "# save FPDF() class into \n",
    "# a variable pdf \n",
    "pdf = FPDF() \n",
    "\n",
    "# Add a page \n",
    "pdf.add_page() \n",
    "\n",
    "# set style and size of font \n",
    "# that you want in the pdf \n",
    "f = open(\"myfile1.txt\", \"r\",encoding=\"latin-1\") \n",
    "\n",
    "pdf.set_font(\"Arial\",\"U\", size = 20) \n",
    "\n",
    "# open the text file in read mode \n",
    "\n",
    "pdf.set_text_color(255,0,0) \n",
    "pdf.cell(200, 10, txt = \"Smart Meet\", ln = 1, align = 'C') \n",
    "\n",
    "pdf.set_text_color(0,0,0) \n",
    "\n",
    "pdf.set_font(\"Times\", size = 10)\n",
    "pdf.cell(200, 10, txt = \"----------------------------------------------------------------------------------------------------------\", ln = 3, align = 'C') \n",
    "pdf.set_font(\"Arial\",\"B\", size = 15)\n",
    "pdf.cell(200, 10, txt = \"Short Summary of your meet !!!\", ln = 5, align = 'C') \n",
    "\n",
    "# insert the texts in pdf \n",
    "pdf.set_font(\"Times\", size = 10)\n",
    "for x in f: \n",
    "    pdf.cell(200, 10, txt = x, ln = 7, align = 'J') \n",
    "# save the pdf with name .pdf\n",
    "\n",
    "pdf.set_font(\"Times\", size = 10)\n",
    "pdf.cell(200, 10, txt = \"-----------------------------------------------------\", ln = 9, align = 'C') \n",
    "pdf.set_font(\"Arial\",\"B\", size = 15)\n",
    "pdf.add_page()\n",
    "pdf.cell(200, 10, txt = \"AI based minutes of your meet !!!\", ln = 11, align = 'C') \n",
    "pdf.set_font(\"Times\", size = 10)\n",
    "\n",
    "f = open(\"myfile2.txt\", \"r\",encoding=\"latin-1\") \n",
    "for x in f: \n",
    "    pdf.cell(200, 10, txt = x, ln = 13, align = 'J')\n",
    "\n",
    "pdf.cell(200, 10, txt = \"-----------------------------------------------------\", ln = 15, align = 'C') \n",
    "pdf.output(\"Smart Meet.pdf\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_mail import sendpdf \n",
    "  \n",
    "# Taking input of following values \n",
    "# ex-\"abcd@gmail.com\"  \n",
    "sender_email_address = \"balajipadamwarp@gmail.com\"\n",
    "  \n",
    "# ex-\"xyz@gmail.com\"  \n",
    "receiver_email_address = input()  \n",
    "  \n",
    "# ex-\" abcd1412\"  \n",
    "sender_email_password = \"**********\" \n",
    "  \n",
    "# ex-\"Heading of email\" \n",
    "subject_of_email = \"Summary by Smart Meet software\"     \n",
    "   \n",
    "# ex-\" Matter to be sent\" \n",
    "body_of_email = \"Please go through the attachment!\" \n",
    "   \n",
    "# ex-\"Name of file\"  \n",
    "filename = \"Smart Meet\"         \n",
    "  \n",
    "# ex-\"C:/Users / Vasu Gupta/ \" \n",
    "location_of_file = \"C:/Users/Balaji Padamwar\"  \n",
    "  \n",
    "  \n",
    "# Create an object of sendpdf function  \n",
    "k = sendpdf(sender_email_address,  \n",
    "            receiver_email_address, \n",
    "            sender_email_password, \n",
    "            subject_of_email, \n",
    "            body_of_email, \n",
    "            filename, \n",
    "            location_of_file) \n",
    "  \n",
    "# sending an email \n",
    "k.email_send()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
